{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter notebook tested on docker tensorflow/tensorflow:2.4.1-gpu-jupyter\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, Reshape, LeakyReLU, Activation \n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION\"] = '1'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        print('{} memory growth: {}'.format(device, tf.config.experimental.get_memory_growth(device)))\n",
    "else:\n",
    "    print(\"Not enough GPU hardware devices available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = 368\n",
    "BATCH_SIZE = 256\n",
    "WORKERS = 36\n",
    "Channel = 3  # color images\n",
    "\n",
    "## Latent space\n",
    "latent_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model ###\n",
    "\n",
    "inputs = Input(shape=(IMG_SIZE, IMG_SIZE, Channel), name=\"inputs\")\n",
    "x = inputs\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(16, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "temp = MaxPool2D((2, 2))(x)\n",
    "\n",
    "x = Flatten()(temp)\n",
    "\n",
    "units = x.shape[1]\n",
    "encoded = Dense(latent_dim, name=\"latent\")(x)\n",
    "\n",
    "x = Dense(units)(encoded)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = Reshape((temp.shape[1], temp.shape[2], temp.shape[3]))(x)\n",
    "\n",
    "x = Conv2DTranspose(8, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = Conv2DTranspose(8, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = Conv2DTranspose(16, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = Conv2DTranspose(32, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = Conv2DTranspose(Channel, (3, 3), strides=1, padding=\"same\")(x)\n",
    "x = Activation(\"sigmoid\", name=\"outputs\")(x)\n",
    "\n",
    "outputs = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncodr\n",
    "autoencoder = Model(inputs, outputs)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder = Model(inputs, encoded)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weight\n",
    "# set path to the trained weight\n",
    "\n",
    "autoencoder.load_weights( #path to 'AutoEncoder_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set image_directory to encode\n",
    "# assumed directory structure is 'YOUR_TEST_DIRECTORY/SUB_DIRECTORY/IMAGES'\n",
    "\n",
    "test_dir = # YOUR_TEST_DIRECTORY\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
    "                                                              samplewise_center=False,\n",
    "                                                              featurewise_std_normalization=False,\n",
    "                                                              samplewise_std_normalization=False,\n",
    "                                                              zca_whitening=False,\n",
    "                                                              zca_epsilon=1e-6,\n",
    "                                                              rotation_range=0,\n",
    "                                                              width_shift_range=0,\n",
    "                                                              height_shift_range=0,\n",
    "                                                              brightness_range=None,\n",
    "                                                              shear_range=0.0,\n",
    "                                                              zoom_range=0.0,\n",
    "                                                              channel_shift_range=0.0,\n",
    "                                                              fill_mode='nearest',\n",
    "                                                              cval=0.0,\n",
    "                                                              horizontal_flip=False,\n",
    "                                                              vertical_flip=False,\n",
    "                                                              rescale=1./255,\n",
    "                                                              preprocessing_function=None,\n",
    "                                                              data_format=None,\n",
    "                                                              validation_split=0.0,\n",
    "                                                              dtype=None)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                                 color_mode='rgb', shuffle=False, batch_size=BATCH_SIZE,\n",
    "                                                 class_mode=None, interpolation='lanczos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = test_generator.filepaths\n",
    "test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncodedImages = encoder.predict(test_generator, workers=WORKERS, verbose=1)\n",
    "EncodedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EncodedImages.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
